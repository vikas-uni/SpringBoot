This is the example showing how to run kafka in docker 

----------to run kafka in docker, clone the repo--------------
https://github.com/wurstmeister/kafka-docker

note- the ip entry in below configuration- 'OUTSIDE://172.20.78.44' is the ip of linux running in windows as WSL 
change docker-compose.yml file-

version: '2'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    expose:
      - "2181"
  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    expose:
      - "9093"
    environment:
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://172.20.78.44:9092
#      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:SASL_PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
#      KAFKA_OPTS: "-Djava.security.auth.login.config=/etc/kafka/kafka_server_jaas.conf"
#      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
#      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
    depends_on:
      - zookeeper
#    volumes:
#      - ./:/etc/kafka

---------------------------------------
then run command-
docker-compose up

------------------------------------

After this, to run springboot client, clone the repo-
https://github.com/layonez/kafka-example

then change in application.yml file-

example:
  kafka:
    consumer-enabled: ${consumer-enabled:true}
spring:
  kafka:
    bootstrap-servers: ${kafka_bootstrap_servers:localhost:9092}
    properties:
      sasl:
        jaas:
          config: org.apache.kafka.common.security.plain.PlainLoginModule required username=${kafka_username:'admin'} password=${kafka_password:'admin-secret'};
        mechanism: PLAIN
      security:
        protocol: PLAINTEXT
    consumer:
      auto-offset-reset: earliest
      group-id: example
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      max-poll-records: 1
      fetch-max-wait: 36000
      enable-auto-commit: false
      client-id: example
    producer:
      client-id: example
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      retries: 2
    jaas:
      enabled: false
    listener:
      poll-timeout: 1800000
      concurrency: 1
      ack-mode: manual_immediate

---------------------------------------------------
more info on this- https://habr.com/en/post/529222/

further example- https://www.baeldung.com/ops/kafka-docker-setup
https://gist.github.com/DevoKun/01b6c9963d5508579f4cbd75d52640a9
https://www.maestralsolutions.com/spring-boot-implementation-for-apache-kafka-with-kafka-tool/
**********************************************
Kafka topics and partitions basics-

https://hevodata.com/learn/kafka-partitions/
https://www.instaclustr.com/blog/a-visual-understanding-to-ensuring-your-kafka-data-is-literally-in-order/
https://newrelic.com/blog/best-practices/kafka-best-practices

scaling kafka instances-
https://dev.to/xiaoyifante/design-the-kafka-architecture-to-handle-1-billion-requests-349c
https://www.confluent.io/blog/optimizing-apache-kafka-deployment/

